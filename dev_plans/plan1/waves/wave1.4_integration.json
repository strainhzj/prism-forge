{
  "_file_type": "integration_guide",
  "_description": "Wave 1 集成指南：集成任务、验证检查点、回滚计划、初始化顺序、API 兼容性",
  "integration_tasks": [
    {
      "task_id": "WAVE1_INTEGRATION",
      "name": "第一波任务集成与合并",
      "description": "验证两个并行任务完成后正确集成",
      "steps": [
        "合并 T1_1 分支到 feat/phase1-wave1（注意解决 Cargo.toml 依赖冲突）",
        "合并 T2_7 分支到 feat/phase1-wave1（注意解决 Cargo.toml 依赖冲突）",
        "解决冲突（如有），特别注意 Cargo.toml 的依赖合并（参考下面的 cargo_toml_merge策略）",
        "运行完整测试套件",
        "更新 main_plan.json 状态：",
        "  - 在 completed_tasks 数组中添加 \"T1_1\" 和 \"T2_7\"",
        "  - 更新 global_status.current_phase 为 \"PHASE_2\"（如果 Wave 1 是第一个阶段）",
        "  - 更新 global_status.overall_progress 为 \"25%\"（基于 Wave 1 完成度）",
        "  - 更新 global_status.last_updated 为当前日期",
        "  - 将 PHASE_1 的 status 改为 \"completed\""
      ],
      "cargo_toml_merge_strategy": {
        "_resource_reference": "dev_plans/plan1/resources/wave1/database/11_git_strategy.md",
        "description": "详细的 Cargo.toml 合并策略和 Git 工作流已提取到资源文件",
        "conflict_resolution": "T1_1 和 T2_7 并行任务都会修改 Cargo.toml，合并时需要手动解决冲突",
        "merged_dependencies_example": {
          "description": "合并后的完整 [dependencies] 部分（简化版，按字母顺序）",
          "content": [
            "anyhow = \"1.0\"",
            "async-openai = \"0.25\"",
            "chrono = { version = \"0.4\", features = [\"serde\"] }",
            "dirs = \"5.0\"",
            "futures = \"0.3\"",
            "glob = \"0.3\"",
            "keyring = { version = \"3.0\", features = [\"windows-native\"] }",
            "log = \"0.4\"",
            "reqwest = { version = \"0.12\", features = [\"json\", \"blocking\", \"stream\"] }",
            "rusqlite = { version = \"0.32\", features = [\"bundled\"] }",
            "secrecy = \"0.10\"",
            "serde = { version = \"1.0\", features = [\"derive\"] }",
            "serde_json = \"1.0\"",
            "sqlite-vec = { version = \"0.5\", features = [\"bundled\"] }",
            "thiserror = \"2.0\"",
            "tiktoken-rs = \"0.5\""
          ],
          "new_dependencies_highlighted": [
            "log = \"0.4\"           # T1_1 新增",
            "sqlite-vec = { version = \"0.5\", features = [\"bundled\"] }  # T1_1 新增",
            "tiktoken-rs = \"0.5\"   # T2_7 新增"
          ]
        },
        "merge_steps": [
          "1. 在 feat/phase1-wave1-t1_1 分支执行 T1_1，添加 sqlite-vec 和 log",
          "2. 在 feat/phase1-wave1-t2_7 分支执行 T2_7，添加 tiktoken-rs",
          "3. 合并 T1_1 分支到 feat/phase1-wave1",
          "4. 合并 T2_7 分支到 feat/phase1-wave1，解决 Cargo.toml 冲突",
          "5. 确保最终依赖列表包含所有 16 个依赖（13 现有 + 3 新增）",
          "6. 运行 cargo check 验证编译通过"
        ]
      },
      "acceptance_criteria": [
        "所有子分支成功合并",
        "cargo test --all 通过",
        "cargo clippy 无警告",
        "cargo fmt 检查通过",
        "应用能正常启动",
        "SELECT vec_version() 返回 0.5.0"
      ]
    }
  ],
  "verification_checkpoints": [
    {
      "checkpoint_id": "CP_WAVE1_DB",
      "name": "数据库验证",
      "commands": [
        "SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;",
        "SELECT vec_version();"
      ],
      "expected_outputs": [
        "api_providers, message_embedding_map, message_embeddings, messages, meta_templates, saved_prompts, sessions, schema_migrations",
        "0.5.0"
      ]
    },
    {
      "checkpoint_id": "CP_WAVE1_TOKEN",
      "name": "Token 计数器验证",
      "commands": [
        "invoke('count_prompt_tokens', { prompt: 'Hello, world!' })"
      ],
      "expected_outputs": [
        "Token count 应约为 3-4（取决于分词器）"
      ]
    },
    {
      "checkpoint_id": "CP_WAVE1_CONCURRENCY",
      "name": "并发访问验证",
      "_reference": "参考 wave1.5_templates.json 中的 concurrent_test_template 获取完整测试代码",
      "test_commands": [
        "运行并发测试: cargo test --test repository concurrent_create_sessions -- --nocapture",
        "运行并发读取测试: cargo test --test repository concurrent_read_sessions -- --nocapture"
      ],
      "expected_outputs": [
        "所有 10 个 Session 创建成功，无死锁",
        "100 次并发查询全部成功，无 Mutex poison 错误",
        "测试输出显示: 'test concurrent_create_sessions ... ok'",
        "测试输出显示: 'test concurrent_read_sessions ... ok'"
      ],
      "verification_sql": [
        "SELECT COUNT(*) FROM sessions; -- 应返回 10（并发创建的记录数）",
        "SELECT COUNT(*) FROM sessions WHERE is_active = 1; -- 验证活跃会话正确"
      ]
    }
  ],
  "rollback_plan": {
    "_resource_reference": "dev_plans/plan1/resources/wave1/database/09_rollback_plan.md",
    "description": "详细的回滚流程已提取到资源文件",
    "steps_summary": "Step 0: 备份 -> Step 1: 恢复 -> Step 2: 回滚版本 -> Step 3: 删除表 -> Step 4: 恢复代码 -> Step 5: 恢复Cargo.toml -> Step 6: 清理缓存 -> Step 7: 验证"
  },
  "rollback_failure_handling": {
    "_resource_reference": "dev_plans/plan1/resources/wave1/database/09_rollback_plan.md",
    "description": "回滚失败处理方案已提取到资源文件"
  },
  "initialization_order": {
    "_resource_reference": "dev_plans/plan1/resources/wave1/database/10_initialization_order.md",
    "description": "详细的初始化顺序和集成指南已提取到资源文件",
    "phases_summary": "Phase 1: 数据库初始化 (get_db_path -> get_connection_shared -> PRAGMA -> sqlite-vec -> run_migrations) -> Phase 2: Tauri状态 (LLMClientManager -> Repository -> app.manage)"
  },
  "api_compatibility_commitments": {
    "保留在JSON中": "Breaking Changes 迁移路径和 API 兼容性承诺是核心集成信息，保留在 JSON 文件中"
  },
  "vector_dimension_migration": {
    "_resource_reference": "dev_plans/plan1/resources/wave1/database/10_initialization_order.md",
    "description": "向量维度迁移策略已提取到资源文件"
  },
  "api_compatibility_commitments": {
    "existing_api": {
      "database::migrations::get_db_path": "保持不变，继续返回 Result<PathBuf>（返回的是路径而非连接）",
      "database::migrations::initialize_database": "Breaking Change: 原函数将被 database::init::get_connection_shared 替代",
      "database::migrations::run_migrations": "保持签名不变，内部扩展支持 v4-v8",
      "database::models::ApiProvider": "完全兼容，不修改现有字段",
      "database::repository::ApiProviderRepository": "Breaking Change: 必须更新为存储 Arc<Mutex<Connection>>，移除 from_default_db()，添加 with_conn()",
      "database::migrations::get_connection": "Breaking Change: 原函数将被 database::init::get_connection_shared 替代"
    },
    "new_api": {
      "database::init::get_db_path": "从 migrations 移动到 init，签名不变",
      "database::init::get_connection_shared": "新增，返回 Result<Arc<Mutex<Connection>>> 全局单例",
      "database::repository::SessionRepository": "新增，提供 Session CRUD",
      "database::repository::MessageRepository": "新增，提供 Message CRUD",
      "database::repository::MessageEmbeddingRepository": "新增，提供向量搜索",
      "tokenizer::count_tokens": "新增，提供 Token 计数功能"
    },
    "migration_compatibility": "支持从 v0, v1, v2, v3 任意版本升级到 v8，迁移幂等性保证",
    "breaking_changes": {
      "database::init::get_connection_shared": "Breaking Change: 替代原 get_connection()，返回 Arc<Mutex<Connection>> 而非 Connection",
      "database::repository::ApiProviderRepository": "Breaking Change: 存储类型从 Connection 改为 Arc<Mutex<Connection>>，构造函数从 new(Connection) 改为 with_conn(Arc<Mutex<Connection>>)",
      "影响的调用方": [
        "所有直接使用 database::migrations::get_connection() 的代码",
        "所有使用 ApiProviderRepository::new() 或 from_default_db() 的代码",
        "所有接收 Connection 参数的 Repository 方法",
        "Tauri 命令中的 State<Connection> 需改为 State<Arc<Mutex<Connection>>>"
      ],
      "migration_path": [
        "1. 更新导入：use database::init::get_connection_shared",
        "2. 修改 Repository 构造：let repo = ApiProviderRepository::with_conn(get_connection_shared()?);",
        "3. 修改内部访问：let db = self.conn.lock().map_err(|e| ...)? 获取 Connection 引用",
        "4. Tauri 命令使用 State<Arc<Mutex<Connection>>> 注入",
        "5. 测试所有调用方确保功能正常"
      ]
    },
    "migration_warnings": [
      "所有使用 Connection 的代码需要更新为使用 Arc<Mutex<Connection>>",
      "获取 Connection 引用必须使用 .lock().map_err() 处理错误，不能使用 .unwrap()",
      "Mutex 可能被 poison，.map_err() 会捕获并转换为错误返回",
      "Arc clone 是廉价操作，可以频繁调用传递给多个 Repository",
      "迁移后务必运行完整测试套件验证功能"
    ]
  },
  "next_wave_dependencies": [
    "WAVE_2: 依赖 T1_1 完成（数据库表结构和 Repository）",
    "WAVE_3: 依赖 T1_1 和 T2_7 完成（数据库 + Token 计数）"
  ],
  "vector_dimension_migration": {
    "current": "384 dimensions (BGE-small-en-v1.5) - used in Wave 1",
    "future_options": [
      "1536 dimensions (OpenAI text-embedding-ada-002)",
      "768 dimensions (BGE-base-en-v1.5)",
      "Custom dimensions based on model choice"
    ],
    "migration_strategy": [
      "1. Data migration requires regenerating all embeddings with new model",
      "2. Use background task to gradually migrate existing embeddings",
      "3. Add vector_dimension column to message_embeddings table for tracking",
      "4. Support dual-format during migration period",
      "5. Archive old embeddings after successful migration"
    ],
    "note": "Vector dimension change is a breaking change that requires careful planning and data migration"
  }
}